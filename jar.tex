\documentclass[a4paper,10pt,runningheads]{llncs}
\usepackage{url}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{upgreek}
\usepackage[mathletters]{ucs}
\usepackage[utf8x]{inputenx}
\usepackage{comment}
\newcommand{\N}{\ensuremath{\mathbbm{N}}}
\newcommand{\Z}{\ensuremath{\mathbbm{Z}}}
\newcommand{\Q}{\ensuremath{\mathbbm{Q}}}
\usepackage{color}

\definecolor{dkblue}{rgb}{0,0.1,0.5}
\definecolor{lightblue}{rgb}{0,0.5,0.5}
\definecolor{dkgreen}{rgb}{0,0.4,0}
\definecolor{dk2green}{rgb}{0.4,0,0}
\definecolor{dkviolet}{rgb}{0.6,0,0.8}

% listings:

\usepackage{listings}
  % The package listingsutf8 supports utf8 for \lstinputlisting
  % However, we do not want to put all our code snippets in separate files.

\def\lstlanguagefiles{defManSSR.tex}
\lstset{language=SSR}
\lstset{literate=
  % symbols that actually occur as unicode in our source:
  {λ}{{$\uplambda\ $}}1
  {∃}{{$\exists$}}1
  {→}{{$\to\ $}}1
  {≠}{{$\ne\ $}}1
  {¬}{{$\neg\ $}}1
  {⟶}{{$\longrightarrow\ $}}1
  {∧}{{$\land$}}1
  {∀}{{$\forall$}}1
  {Π}{{$\Uppi\ $}}1
  {η}{{$\upeta$}}1
  {⊓}{{$\sqcap$}}1
  {∘}{{$\circ\ $}}1
  {◎}{{$\odot\ $}}1
  % things we can't make pretty in the actual source, but can make pretty here!:
  {=>}{{$\,\Rightarrow\ $}}1
  {==>}{{$\Rightarrow\ $}}1
  {<-}{{$\leftarrow\ $}}1
}


\begin{document}
\title{The algebraic hierarchy in type theory using type classes}
\author{Bas Spitters \and Eelis van der Weegen}
\institute{Radboud University Nijmegen}
\date{today}
\maketitle
\begin{abstract}
We present a new formalization of the algebraic hierarchy in Coq, exploiting its new type class mechanism to make practical a solution formerly thought infeasible. Our approach addresses both traditional challenges as well as new ones resulting from our ambition to build upon this development a library of constructive analysis in which abstraction penalties inhibiting efficient computation are reduced to a bare minimum. To support mathematically sound abstract interfaces for $\N$, $\Z$, and $\Q$, our formalization includes portions of category theory and multisorted universal algebra.
Algebra flourishes by the interplay between syntax and semantics. The Prolog-like
abilities of type class unification allow us to conveniently define a quote function thus facilitating the use of reflective techniques.
\end{abstract}

\section{Introduction}
The development of libraries for formalized mathematics presents many software engineering challenges~\cite{C-corn,DBLP:conf/types/HaftmannW08}, because it is far from obvious how the clean, idealized concepts from everyday mathematics should be represented using the facilities provided by concrete theorem provers and their formalisms, in a way that is both mathematically faithful and convenient to work with.

For the algebraic hierarchy---a critical component in any library of formalized mathematics---these challenges include structure inference, handling of multiple inheritance, idiomatic use of notations, and convenient algebraic manipulation.

Several solutions have been proposed for the Coq theorem prover: dependent records~\cite{DBLP:journals/jsc/GeuversPWZ02} (a.k.a. telescopes), packed classes~\cite{Packed}, and occasionally modules. We present a new approach based entirely on Coq's new type class mechanism, and show how its features together with a key design pattern let us effectively address the challenges mentioned above.

Since we intend to use this development as a basis for constructive analysis with practical certified exact real arithmetic, an additional objective and motivation in our design is to facilitate \emph{efficient} computation. In particular, we want to be able to effortlessly swap implementations of number representations. Doing this requires that we have clean abstract interfaces, and mathematics tells us what these should look like: we represent $\N$, $\Z$, and $\Q$ as \emph{interfaces} specifying an initial semiring, an initial ring, and a field of integral fractions, respectively.

To express these elegantly and without duplication, our development\footnote{The sources are available
at:~\url{http://www.eelis.net/research/math-classes/}} includes an integrated formalization of parts of category theory and multi-sorted universal algebra, all expressed using type classes for optimum effect.

\section{The Type-Classified Algebraic Hierarchy}\label{classes}
Unlike Haskell's and Isabelle's second class type classes, Coq's type classes are first class~\cite{DBLP:conf/tphol/SozeauO08}: classes and their instances are realized as ordinary record types (``dictionaries'') and registered constants of these types.

We represent each structure in the algebraic hierarchy as a type class. This immediately leads to the familiar question of which components of the structure should become parameters of the class, and which should become fields. By far the most important design choice in our development is the decision to turn all \emph{structural} components (i.e. carriers, relations, and operations) into parameters, keeping only \emph{properties} as fields. Type classes defined in this way are essentially predicates with automatically resolved proofs.

Conventional wisdom warns that while this approach is theoretically very flexible, one risks extreme inconvenience both in having to declare and pass around all these structural components all the time, as well as in losing notations (because we no longer project named operations out of records). These legitimate concerns will be addressed in Sections~\ref{bundle}-\ref{classes}. Section~\ref{univ} abstracts to universal
algebra, we develop the basic theory to the point of the first homomorphism theorem.
Section~\ref{interfaces} provides interfaces to usual data structures by providing their universal
properties. To allow symbolic manipulation of semantic objects one needs a quote function. Usually,
this function is implemented in Coq's tactics language. A more convenient way is to use type class
unification; see section~\ref{quote}. In section~\ref{canonical}, we end with a short comparison
between type classes and canonical structures.

In this paper we focus on the Coq proof assistant. We conjecture that the methods can be transferred
to any type theory based proof assistant supporting type classes such as
Matita~\cite{asperti2007user}.

\section{Preliminaries}
\subsection{Coq type theory}
The Coq proof assistant is based on the calculus of inductive
constructions~\cite{CoquandHuet,CoquandPaulin}, a dependent type theory with (co)inductive types; see~\cite{Coq,BC04}.

The Coq type theory lacks quotient
types, as it would make type checking undecidable. Instead it supports setoids (aka Bishop sets), a pair of a type and an equivalence relation~\cite{Bishop67,Hofmann,Capretta}. Recently, improved support for setoids has been added to the system~\cite{Setoid-rewrite}. Functions respecting these equivalence relations are called \lstinline|Proper|.
As we will see in Section~\ref{univ} below this functionality can also be used to work with
quotient algebras.

Coq has two kinds of sorts \lstinline|Prop| for propositions and \lstinline|Type| for data types. Coq
is scheduled to support proof irrelevance, every \lstinline|p,q:P:Prop| are
convertible, in the future; see section~\ref{PI}.

% \subsection{Type classes}
% Implementation in Ltac, Notation etc\\
% Coercions\\
% Unification hints

\section{To bundle or not to bundle? (Or: What to bundle?)}\label{bundle}
We provide a rationale for our approach. We begin gently.

How should we define reflexive, transitive, and symmetric relations? In a first attempt, we might define:
\begin{lstlisting}
  Record ReflexiveRelation: Type :=
    { rr_carrier: Type
    ; rr_rel: relation rr_carrier
    ; rr_proof: Π x, rr_rel x x }.
\end{lstlisting}
 
and similar for transitive and symmetric relations.

With this approach, we run into problems when defining \lstinline|EquivalenceRelation| in terms of
\lstinline|ReflexiveRelation| and its two siblings, because when posit three objects of type
\lstinline|ReflexiveRelation|, \lstinline|TransitiveRelation|, and \lstinline|SymmetricRelation|, respectively, we have to
add equalities expressing that they talk about the same carrier and relation. These equalities
cause difficulties, because the three carriers and relations won't be convertible.
Technically, this leads to the research in manifest fields, i.e.\ the \emph{with} construction, to
which we return in Section~\ref{manifest}.

As a first step we would define \lstinline|ReflexiveRelation| as:
\begin{lstlisting}
  Record ReflexiveRelation (carrier: Type): Type :=
    { rr_rel: relation rr_carrier
    ; rr_proof: Π x, rr_rel x x }.
\end{lstlisting}

This would solve the problem for the carrier, but \lstinline|EquivalenceRelation| would still need equalities for the relation:
\begin{lstlisting}
  Record EquivalenceRelation: Type :=
    { er_carrier: Type
    ; er_refl: ReflexiveRelation er_carrier
    ; er_sym: SymmetricRelation er_carrier
    ; er_trans: TransitiveRelation er_trans
    ; same_rel: rr_rel er_refl = sr_rel er_sym
    ; same_rel': rr_rel er_refl = tr_rel er_trans }.
\end{lstlisting}


A natural solution is to pull the relation out of \lstinline|ReflexiveRelation| (and its siblings) as well:
\begin{lstlisting}
  Record ReflexiveRelation (carrier: Type) (rel: relation carrier): Prop :=
    { rr_proof: Π x, rr_rel x x }.
\end{lstlisting}

or equivalently:
\begin{lstlisting}
  Definition ReflexiveRelation (carrier: Type) (rel: relation carrier): Prop :=
    Π x, rr_rel x x.
\end{lstlisting}

This is how reflexivity is defined in the standard library, and this is entirely sensible. The
change from \lstinline|Type| to \lstinline|Prop| reflects the fact that \lstinline|ReflexiveRelation| is now strictly a property,
proofs of which can be nicely kept opaque;%
\footnote{Coq distinguishes between transparent and opaque definitions. The former can be unfolded,
whereas this is impossible for the latter. Since we never need to distinguish between two proofs of
a propositions, propositions can be opaque.}
we will return to this issue in Section~\ref{PI}.
We can now define \lstinline|EquivalenceRelation| without awkward equalities:
\begin{lstlisting}
  Record EquivalenceRelation: Type :=
    { er_carrier: Type
    ; er_rel: relation er_carrier
    ; er_refl: ReflexiveRelation er_carrier er_rel
    ; er_sym: SymmetricRelation er_carrier er_rel
    ; er_trans: TransitiveRelation er_trans er_rel }.
\end{lstlisting}


But looking at \lstinline|EquivalenceRelation|, we see that it now essentially has the same form as the
original naive \lstinline|ReflexiveRelation| record we started with. Clearly, equivalence relations
and reflexive relations are analogous concepts, and by the same argument we
conclude that \lstinline|EquivalenceRelation| should really be defined as:

\begin{lstlisting}
Record EquivalenceRelation (er_carrier: Type)
                             (er_rel: relation er_carrier): Prop :=
  { er_refl: ReflexiveRelation er_carrier er_rel
  ; er_sym: SymmetricRelation er_carrier er_rel
  ; er_trans: TransitiveRelation er_trans er_rel }.
\end{lstlisting}


After all, when we define a type with
two different equivalence relations on it,
such as the quotient of a setoid,
we have the same considerations as for \lstinline|ReflexiveRelation| above.

At the risk of overstressing the point, let us look at how the same problem and solution keep
appearing in composite structures. Suppose we use a definition of \lstinline|Monoid| that bundles the
relation. Then if we proceed to define \lstinline|SemiRing| as a double \lstinline|Monoid|, we face a dilemma:
\begin{lstlisting}
  Record SemiRing A: Type :=
    { mult_monoid: Monoid A 
    ; plus_monoid: Monoid A 
    ; plus_comm: Commutative (mon_op plus_monoid)
    ; mult_comm: Commutative (mon_op mult_monoid)
    ; mult_0_l: Π x: A, H
\end{lstlisting}

Do we use \lstinline|mult_monoid|'s equality or \lstinline|plus_monoid|'s equality in \lstinline|H|?
Again, for this definition to be usable at all, we would need to add an equality expressing that the
two monoids contain the same equivalence relation. And again, the proper solution is to change
Monoid and unbundle the relation. But here, we have a choice as to how much we unbundle exactly.
(For the moment we ignore the question of whether the unit and binary operator should be unbundled
as well, focusing only on the equivalence relation and its equivalence proof.)

% We \emph{could} become over-eager and decide to unbundle the equivalence proof term as well:
% \begin{lstlisting}

% Record Monoid (A: Type) (R: A → A → Prop)
%   (e: Equivalence R) : Type := ...
% \end{lstlisting}

% However, this way if we happen to have two proofs |p| and |q| that a certain relation is an
% equivalence, we end up with two non-convertible ways to express that the relation (together with
% some unit and binary operation) form a Monoid: 'Monoid A R p ...' and 'Monoid A R q ...'. We must
% either try to deal with this (by proving that Monoid proofs with different Equivalence proofs are
% interchangable, and hope for automation, such as type class instance resolution, to use them
% interchangably), or take great care to ensure that |Equivalence| proof terms are always shared,
% essentially elevating them to `values', which goes against the principle of proof
% irrelevance.\marginpar{What if we add proof irrelevance?}
% BOTTOMLINE: Bundle as much as we can!
% 
% Neither of these options are very appealing. We really should just make |Monoid| take as
% parameters
% only the operations/relations. If we treat the monoid's unit and binary operation the same way,
% this
% means that |Monoid| ends up in |Prop|, and that its instances can be left opaque, which is really
% how things ought to be.

Another benefit of our approach is that it works very smoothly when these records are in fact type
classes. When relations and operations are bundled and do \emph{not} appear as parameters of the
structure record/class, to express that some collection of relations and
operations possess the structure as a type class constraint seems to require manifest fields; see
Section~\ref{manifest}. With
our unbundled approach, on the other hand, such type class constraints are easily expressed without
any extensions as type inhabitation queries
% (e.g. ``hey Coq, find me a proof of [Monoid some_rel some_op some_unit]'')
of types living in Prop, so that we don't even care what instances are found (thus embracing proof
irrelevance).

Leaving the equivalence proofs bundled means that when one has a proof that a structure
is a semiring, one has two proofs (via the two monoids) that the equivalence relation is an
equivalence. Fortunately, this redundancy is entirely harmless since our terms
never refer (directly or indirectly) to proofs, which is the case when the relations and operations
they are composed from are left unbundled. Here, too, we enjoy the warm embrace of proof
irrelevance.

From the discussion so far, we derive some principles:
\begin{enumerate}
 \item structural concepts (like Reflexive, Setoid, Monoid) should have their structural components
(i.e. carriers, relations, and operations) as parameters, and nothing else;
 \item (as a consequence) these concepts should be defined as predicates (which includes records and
classes living in Prop), and their proofs may be kept opaque;
 \item (as a second consequence) algebraic expressions need/should never refer (directly or
indirectly) to proofs about the algebraic structure.\footnote{The reciprocal in a field
famously does refer to a proof that the element is non-zero, but not to a proof that the operations
indeed form a field.}
\end{enumerate}
% \setcounter{enumi}{3}

The principles listed so far are not particularly controversial, in fact this
approach ensures maximum flexibility~\cite{Hints}. However,
there is a common perception that unbundling carriers, relations, and operations this way invariably
leads either to unmanageably big algebraic expressions (involving endless projections and/or implicit
arguments), or to unmanageably long and tedious enumeration of carriers/relations/operations, or to
problems establishing canonical names for operations (since we no longer project them out of
structure instances all the time).

In the next sections, we show how systematic use of type classes (and their support infrastructure
in Coq), combined with the use of a special form of type class we call an `operational type class'
(as opposed to a `structural' type class we might use in place of the records shown thus far), lets
us avoid these problems.

\section{Managing unbundled structure with type classes}

So far, we have only looked at the definitions of the structures themselves, and have not yet
considered their use when proving theorems about these structures.
We would like to approximate the common mathematical vernacular, where one
simply says:

for $x, y, z$ in a semigroup $G$, $x * y * z = z * y * x$, $\ldots$

Suppose we have defined \lstinline|SemiGroup| in line with the aforementioned principles:
\begin{lstlisting}
Record SemiGroup (A: Type) (eq: A $\to$ A $\to$ Prop)
 (op: A $\to$ A $\to$ A): Prop := ...
\end{lstlisting}

Then our starting point is the obvious but awful:
\begin{lstlisting}
Lemma perm A eq op (P: SemiGroup A eq op) x y z:
                   eq (op (op x y) z) (op (op z y) x).
\end{lstlisting}

As a first cleaning measure, we might hope to introduce some notations to let us use infix notation
for the semigroup operator (say, \lstinline|&|) and for equality. Unfortunately, at this point the names \lstinline|eq| and \lstinline|op| are just local names and there is no way to predeclare that they are to be associated with any notation. What we really need are canonical names for these notions, so that we may fashion notations for them.

This is a typical job for type classes, and they are used in this way in the \lstinline|Clean| standard
library. Similarly, Haskell uses type classes to overload notations.
We simply follow suit:
\begin{lstlisting}
  Class Equiv A := equiv: relation A.
  Class SemiGroupOp A := sg_op: A $\to$ A $\to$ A.

  Infix "=" := equiv: type_scope.
  Infix "&" := sg_op (at level 50, left associativity).
\end{lstlisting}

We choose to use \lstinline|&| here and reserve the notation \lstinline|*| for ring multiplication. We use = for setoid equality, since Leibniz equality seems less important for the formalization of
mathematics. More precisely, setoid equality is the basic concept. In some special cases, one can prove
that setoid equality coincides with Leibniz equality.
%Listings don't seem to work will with footnotes.
We would have like to use a haskell style definition
\begin{lstlisting}
Class Equiv A := (=): relation A.
\end{lstlisting}
Unfortunately, currently this is not supported in Coq.

These single-field type classes are given special treatment in that they are not translated into
records the way classes with any other number of fields are, but are instead turned into ordinary
definitions. The effect of this is that \lstinline|Equiv A| immediately reduces to \lstinline|relation A|, and that the equiv `projection' is the identity function whose argument is inferred using instance resolution. Thus, for a very modest cost in indirection, we gain the ability to use canonical names, and with it, notations:
\begin{lstlisting}
Record SemiGroup (A: Type) (eq: Equiv A)
                 (op: SemiGroupOp A): Prop := ...
Lemma perm A eq op (P: SemiGroup A eq op) x y z:
                 x & y & z = z & y & x.
\end{lstlisting}

We call these type classes \emph{operational type classes}. We note that operational type classes
allow us to avoid Coq's notation \lstinline|scope| mechanism.

Although the expression now \emph{looks} like it is bound to some
specific semigroup structure (which with traditional approaches would imply projections from bundles
and/or reference to proofs), it is really only referring near-directly to the actual operations
involved, with the semigroup proof existing only as opaque `knowledge about the operations' which we
may use in the proof. This lack of projections keeps our terms small and independent, and keeps
rewriting simple and sane; see Section~\ref{canonical}.

On the other hand, it \emph{does} mean that all the carriers/relations/operations end up in the
context. The context for \lstinline|perm| looks like:
\begin{lstlisting}
  A: Type
  eq: Equiv A
  op: SemiGroupOp A
  P: SemiGroup A eq op
\end{lstlisting}


While we are not particularly worried about overly large contexts (we feel that this will most
likely not be problematic for any but the most complex formalizations), having to \emph{declare}
these entities (like \lstinline|eq| and \lstinline|op| for \lstinline|perm|) \emph{is} a bit of a chore. Fortunately, Coq provides a feature called implicit generalization, which is exactly what we need.
With it, we can write \lstinline|perm| as follows:
\begin{lstlisting}
  Lemma perm `(SemiGroup A) x y z: x & y & z = z & y & x.
\end{lstlisting}

Thus, we have reached the mathematical ideal we aimed for.

\section{Putting it all together}\label{classes}
Combining the ideas in the previous sections we end up with a formalization of algebraic
structures where we use the structure as (implicit) parameters, but
pack the proofs. This can be nicely organized by using canonical names. For instance, we define:
\begin{lstlisting}
Class SemiRing A {e: Equiv A}{plus: RingPlus A}{mult: RingMult A}
                 {zero: RingZero A}{one: RingOne A}:Prop :=
  { semiring_mult_monoid:> Monoid A (op:=mult)(unit:=one)
  ; semiring_plus_monoid:> Monoid A (op:=plus)(unit:=zero)
  ; semiring_plus_comm:> Commutative plus
  ; semiring_mult_comm:> Commutative mult
  ; semiring_distr:> Distribute mult plus
  ; mult_0_l: Π x, 0 * x = 0 }.
\end{lstlisting}

where e.g.\ \lstinline|RingPlus| is the operation class for the semigroup operator.
The notation \lstinline|:>| makes \lstinline|semiring_mult_monoid| a subclass: when asked for a monoid it suffices to
provide a ring.

Having argued that the \emph{all-structure-as-parameters} approach \emph{can} be made practical, we enumerate some of the benefits that make it worthwhile.

First, multiple inheritance becomes trivial: \lstinline|SemiRing| inherits two \lstinline|Monoid| structures on the same carrier and setoid relation, using ordinary named arguments to achieve ``manifest fields''; see section~\ref{manifest}.

Second, because our terms are small and independent and never refer to proofs, we are invulnerable to concerns about efficiency and ambiguity of projection paths that plague existing solutions, obviating the need for extensions like the proposed coercion pullbacks~\cite{Hints}.

Third, since our structural type classes are mere predicates, overlap between their instances is a non-issue. Together with the previous point, this gives us tremendous freedom to posit multiple structures on the same operations and relations, including ones derived implicitly via subclasses: by simply declaring a \lstinline|SemiRing| class instance showing that a ring is a semiring, results about semirings immediately apply implicitly to any known ring, without us having to explicitly encode this relation in the hierarchy definition itself, and without needing any projection or translation of carriers or operations.

Fourth, \emph{Structure-as-parameters} helps setoid-rewriting: type class resolution
can find the equivalence relation in the context.\footnote{
A similar style should be possible for, say, the \lstinline|Ring| tactic, instead of
declaring the ring structure by a separate command, we would rely on type class resolution to find it.}
We note that \lstinline|op| does not depend on the proof that \lstinline|e| is an equivalence. As explained above we use Coq's implicit quantification (\lstinline|`{}|) to avoid having to write all the parameters when \emph{stating} a theorem and Coq's maximally inserted implicit arguments to find the parameters when \emph{applying} a theorem. Both features are new in Coq and stem from the type class implementation.

We mention the trade-off between bigger contexts versus bigger terms. Our contexts are bigger than
those of telescopes or packed classes. In our experience, this has been relatively
harmless\footnote{However, Coq's data structure for contexts is not very efficient. Gonthier fears that this
may be a bottleneck for huge developments. It seems that the data structure chosen
in~\cite{asperti2009compact} will behave better.}%
: most terms in the context are there to support canonical names. Bigger terms
\emph{do} cause problems: 1. when proofs are part of mathematical objects we need to share these
proofs to allow rewriting. Moreover, it prohibits Opaque proofs and `proof irrelevance'. 2. The
projection paths may not be canonical.

Coercion pullbacks~\cite{Hints} were introduced to address problems with multiple coercions paths,
as in the definition of a semiring: a type with two monoid structures on it. We avoid some
of these problems by explicitly specifying the fields. We emphasize that the semiring properties are
automatically derived from the ring properties, although the properties of a semiring are not
structurally included in the ring properties.

Let us now stop and think to what extent this approach suffers from all the problems commonly
associated with it. In particular, let us imagine what happens to our terms and contexts when we
want to talk about nested structures such as polynomials over the ring. For a concrete
representation of the polynomials the context will just contain the context for an abstract ring.
For abstract reasoning about polynomials the context will grow with abstract operations on
polynomials. Consequently, the context will grow linearly, as opposed to exponentially.

\subsection{Manifest fields}\label{manifest}

Manifest fields in records allow us to fix a field of a dependent record. For example, in the
example above one would write \lstinline|Monoid with op=mult|. 
Luo~\cite{DBLP:conf/types/Luo08} has proposed coercive subtyping to implement manifest fields.
It was conjectured~\cite{Hints} that implementing the algebraic hierarchy with type classes in this way would
be awkward due to problems with equality. We avoided these problems by shifting the fields
from the dependent record to its argument, thus mimicking manifest fields by using type classes.
Since \lstinline|op| is \emph{instantiated} with \lstinline|mult|, we need not worry about the
equality \lstinline|op=mult|. This seems to be a general phenomenon. For instance, instead of searching
for a \lstinline|Monoid with op=mult| we would use type class resolution to find an instance of \lstinline|Monoid mult|.
We have thus addressed the problem of multiple inheritance.

\section{Universal algebra}\label{univ}
Motivated originally by our desire to cleanly express interfaces for basic numeric data types such as $\N$ and $\Z$ in terms of their categorical characterization as initial objects in the categories of semirings and rings, respectively, we initially introduced only the very basics of category theory into our development, again using type classes where possible to achieve the same benefits mentioned before.

Realizing that much code duplication for the various algebraic structures in the hierarchy could be avoided by employing universal algebra constructions, we then proceeded to formalize some of the theory of multisorted universal algebra and equational theories, using it to automatically construct varieties of algebras. We avoided existing formalizations~\cite{DBLP:conf/tphol/Capretta99,dominguez2008formalizing} of universal algebra, because we aimed to find out what level of elegance, convenience, and integration can be achieved using the state of the art technology (of which type classes are the most important instance).

At the time of writing, our development includes a fully integrated formalization of a nontrivial portion of category theory and multisorted universal algebra, including various categories (e.g.\ the category \lstinline|Cat| of categories, and finitary algebraic categories  defined by a theory which we instantiate to obtain the categories of monoids, semirings, and rings), functors (including automatically generated forgetful functors), natural transformations, adjunctions, initial models of equational theories constructed from term algebras, transference of proofs between isomorphic models of equational theories, subalgebras, congruences, quotients, products, and the first homomorphism theorem~\cite{meinke1993universal}.

We consider the first homomorphism theorem in more detail:
\begin{theorem}[First homomorphism theorem]
If $A$ and $B$ are algebras, and $f$ is a homomorphism from $A$ to $B$, then the equivalence relation defined by $a\sim b$ if and only if $f(a)=f(b)$ is a congruence on $A$, and the algebra $A/\sim$ is isomorphic to the image of $f$, which is a subalgebra of B.
\end{theorem}

% theory/ua_subalgebraT.v
% find . -iname "*.v" |xargs grep "niverse"
We define congruence:
\begin{lstlisting}
Class Congruence: Prop :=
    { congruence_proper:> Π s, Proper (equiv ==> equiv ==> iff) (e s)
    ; congruence_quotient:> @Algebra et v e _
    }.
\end{lstlisting}

In set theory, a quotient is defined as a collection of equivalence classes. In type theory, a quotient is more naturally
defined by changing the equality, while leaving the carrier unchanged.%
\footnote{In Bishop's words~\cite[p.12]{Bishop/Bridges:1985}: The axiom of choice is used to extract
elements from equivalence classes where they should never have been put in the first place.}
 In this way we profit from the infrastructure for setoids: A congruence relation is coarser than the setoid relation, as indicated by the use of \lstinline|Proper| above.

Alternatively, we could have stated the compatibility of the relation \lstinline|e| by stating that the
relation as a set of pairs is a subalgebra in the product algebra. We have proved that both approaches
are equivalent. As said, the present definition seems natural in type theory. 

Coq provides different sorts. To simplify the discussion, we assume that there are only two sorts:
\lstinline|Prop|, for propositions, and \lstinline|Type|, for data types. A subalgebra is defined by a predicate on the algebra, that is a map \lstinline|A->Prop|. However, the image $Im f:=\{b:B \mid \exists a. b=(f a)\}$ is informative (in \lstinline|Type|) as it includes a witness for the existential. This witness is needed to map $b\in Im f$ to one of its pre-images in $A$. We thus need two flavors of subalgebras, one \lstinline|Prop|-valued an one \lstinline|Type|-valued; see also~\cite{coquand-towards}. Coq provides universe polymorphism for inductive types to avoid code duplication in such cases. Unfortunately, definitions and fixpoints are not (yet?) polymorphic. Hence we had to resort to changing some Fixpoints into Inductives.

Having discussed the first homomorphism theorem we now turn to category theory which helps to organize our development of universal algebra. 

\subsection{Category theory}\label{cats}
Using type classes, we provide a basic library for category theory: categories, functors,
adjunctions, monads,\ldots We follow the usual type theoretical definition of a
category~\cite{saibi1995constructive}.

% \newcommand{\rightarrowtext}{\ensuremath{\rightarrow}}
% \newcommand{\textocirc}{\ensuremath\circ}
%interfaces/abstract_algebra.v

\begin{lstlisting}
Class Category O `{!Arrows O} `{Π x y: O, Equiv (x ⟶ y)}
    `{!CatId O} `{!CatComp O}: Prop :=
  { arrow_equiv:> Π x y, Setoid (x ⟶ y)
  ; comp_proper:> Π x y z,
    Proper (equiv ==> equiv ==> equiv) comp
  ; comp_assoc w x y z (a: w ⟶ x) (b: x ⟶ y) (c: y ⟶ z):
      c ◎ (b ◎ a) = (c ◎ b) ◎ a
  ; id_l `(a: x ⟶ y): cat_id ◎ a = a
  ; id_r `(a: x ⟶ y): a ◎ cat_id = a }.
\end{lstlisting}

This is based on the 2-categorical idea that we have equality on arrows, but not on objects.
Similarly, we have equality on natural transformations, but not on functors.

%theory/categories.v
Natural transformations are formalized as:
\begin{lstlisting}
   Context `{Category C} `{Category D}
   `{!Functor (F: C ⟶ D) Fa} `{!Functor (G: C ⟶ D) Ga}.
   Class NaturalTransformation (η: Π c, F c ⟶ G c): Prop :=
     natural: Π (x y: C) (f: x ⟶ y), η$$ y ∘ fmap F f = fmap G f ∘ η$$ x.
\end{lstlisting}
  % Todo: Having to add "$$" to get whitespace is awful. we can't add "\ " in η's literate-replacement though, because then we also get space before the colon in "η: t".
 
Here \lstinline|fmap F| explicitly refers to the arrow part of the functor \lstinline|F|.
In mathematics one would apply $F$ to both objects and arrows ($F x$, $F f$). However, this does
not seem to fit with type theory as the type of \lstinline|fmap F| depends on the object part of
\lstinline|F|.

We have defined the category of setoids, the dual of a category, products, and hence co-products. 
We prove that two definitions of adjunction are equivalent. The proofs are concise and follow the textbooks.

The usual size problems in the definition of the category of categories can be avoided by using universe polymorphism. 
However, we need to avoid making \lstinline|Relation| a \lstinline|Definition|, since \lstinline|Definitions| are not (yet?) universe polymorphic.

\subsection{Categorical universal algebra}
Having discussed category theory, we now turn to its application to universal algebra.

%varieties/closed_terms.v
We define the forgetful functor $U$ from the category of τ-algebras to the category of sets and its left-adjoint $F$: the term algebra consisting of closed terms, i.e.\ terms with the empty type as set of variables. This term algebra is the initial τ-algebra. Every adjunction defines a monad by composition of the functors $U$ and $F$. We will use the resulting expression monad in Section~\ref{quote} below.


One may hope that this term algebra could be useful to \emph{define} inductive data types, say, to define the natural numbers 
as the term algebra for the theory of semirings. However, it seems difficult to prove decidability of equality, 
as this requires a normalization procedure.

%The product of two $\tau$-algebras is their categorical product.

\begin{comment}
Given a sub\emph{set} of an algebra, we define the sub\emph{algebra} generated by it.
An interesting fact to mention is the use of the following heterogeneous equality between
elements of the algebra and of the subalgebra, i.e.\ terms of different types may be equal.
\begin{lstlisting}
  Fixpoint heq {o}: op_type carrier o -> op_type v o -> Prop :=
    match o with
    | constant x => fun a b => `a == b
    | function x y => fun a b => forall u, heq (a u) (b (`u))
    end.
\end{lstlisting}
\end{comment}

We connect the abstract theory to the concrete theory. Concretely, let $\tau_m$ be the theory
of monoids. Given a (concrete) monoid, we can construct the corresponding $\tau_m$-algebra. 
Conversely, given a $\tau_m$-algebra, we construct an instance of the \lstinline|Monoid| type class.
%varieties/monoid.v
\begin{lstlisting}
Variable o: variety.Object theory.
Global Instance: SemiGroupOp (o tt) := algebra_op theory mult.
Global Instance: MonoidUnit (o tt) := algebra_op theory one.
Global Instance from_object: Monoid (o tt).
\end{lstlisting}

In the last line, instance resolution `automatically' finds the operation and the unit specified in
the lines before.

This interplay between concrete algebraic structure and their expressions on the one hand, and models of equational theories on the other is occasionally a source of tension (in that translation in either direction is not yet fully automatic). However, it opens the door to the possibility of fully internalized implementations of generic tactics for algebraic manipulation, no longer requiring plugins. We come back to this when we describe automatic quotation of concrete expressions into universal algebra expressions; see Section~\ref{quote}.


\section{Interfaces using category theory}\label{interfaces}\label{modul}
We have characterized the naturals as the initial object in the category of semirings and derived
many of their properties from this interface. Unary, binary and machine numbers are
instances of this interface, so we can directly apply these results to all these instances.
Similarly, the integers are the initial ring. The rationals are the field of fractions of the
integers. 
Given a ring $R$, the $R$-algebra $R[X]$ of polynomials, is the free $R$-algebra on a set $X$.
We provide two implementations of polynomials: the
standard representation using lists of coefficients and the Bernstein representation. A Bernstein
basis polynomial is one of the form:
\[b_{\nu,n}(x) = {n \choose \nu} x^{\nu} \left( 1 - x \right)^{n - \nu}, \quad \nu = 0, \ldots, n.\]
A Bernstein polynomial is a linear combination of these basic polynomials. Bernstein polynomials
have been used for efficient computations inside the Coq system~\cite{ZumkellerPhD}.

We encourage more efficient implementations by assigning the default implementation a
low priority. For example, the distance function on the natural numbers, which is derived from its
semiring structure, is assigned priority 10.
\begin{lstlisting}
  Global Program Instance: NatDistance N | 10 := ...
\end{lstlisting}

In future work we aim to base our development of the reals
on an abstract dense set, allowing us to use the efficient dyadic
rationals~\cite{boldo2009combining} as a base for exact real number computation in
Coq~\cite{Riemann,Oconnor:real}. The use of category theory has been important in these developments.

\section{Type class quoting}\label{quote}
Unification hints~\cite{Hints} allow one to semi-automatically construct a quote
function.\footnote{Gonthier provides similar functionality using canonical structures.} This feature is absent from Coq. Fortunately, type classes provide similar functionality as we will now show.

We define a term language for monoids
\begin{lstlisting}
Inductive Expr (V: Type) := Mult (a b: Expr V) | Zero | Var (v: V).
\end{lstlisting}

The expression type is parametrized over the set of variable indices. Hence, we diverge from~\cite{Hints}, 
which uses \lstinline|nat| for variables thereby introducing bound problems and dummy variables.

 An expression is only meaningful in the context of a variable
assignment:\footnote{Categorically: \lstinline|nat| is
an \lstinline|Expr|-algebra and \lstinline|eval| is \lstinline|map vars| composed with the algebra map.}
\begin{lstlisting}
Definition Value := nat.
Definition Vars V := V → Value.

Fixpoint eval {V} (vs: Vars V) (e: Expr V): Value :=
  match e with
  | Zero => 0
  | Mult a b => eval vs a * eval vs b
  | Var v => vs v
  end.
\end{lstlisting}

%Monads are trees with grafting~\cite{MonadsGrafting}: the tree monad
%$TX:=1+T^2X$, may be seen as the prototypical monad. 
The \lstinline|Expr| monad, i.e.\ the free \lstinline|Expr|-algebra monad\footnote{on the category of \lstinline|Type|s with extensional functions.%\marginpar{Proof in classquote}
}, provides a bind operation which describes the arrows in the Kleisli category. Concretely,
\begin{lstlisting}
Fixpoint bind {V W} (f: V → Expr W) (e: Expr V): Expr W :=
  match e with
  | Zero => Zero
  | Mult a b => Mult (bind f a) (bind f b)
  | Var v => vs v
  end.
\end{lstlisting}


% We have shown that |Expr|, i.e.\ |bind| together with |Var|, is a monad on the category of Types
% with extensional functions between them~\marginpar{Really?}.

\noindent We define some simple combinators for variable packs:
%
\begin{lstlisting}
Definition novars: Vars False := False_rect _.
Definition singlevar (x: Value): Vars unit := λ _ => x.
Definition merge {A B} (a: Vars A) (b: Vars B): Vars (A+B) :=
  λ i => if i then a j else b j.
\end{lstlisting}


\noindent These last two combinators are the `constructors' of an implicitly defined subset of
 Galina terms, representing heaps, for which we implement syntactic lookup with type classes.
The heap can also be defined explicitly, with no essential change in the code.
Given a heap and value, \lstinline|Lookup| instances give the value's index in the heap:
% \marginpar{A
% canonical structures approach would allow us to do this in Coq?}
\begin{lstlisting}
  Class Lookup {A} (x: Value) (f: Vars A) :=
    { lookup: A; lookup_correct: f lookup = x }.
\end{lstlisting}

% Context (x: Value) {A B} (va: Vars A) (vb: Vars B).

If the heap is a merge of two heaps and we can find the value's index in the left heap, we can
access it by indexing the merged heap (and vice versa)
\begin{lstlisting}
  Global Instance lookup_left `{!Lookup x va}: Lookup x (merge va vb)
    := { lookup := inl (lookup x va) }.
\end{lstlisting}

If the heap is just a singlevar, we can easily index it.
\begin{lstlisting}
Global Program Instance: Lookup x (singlevar x) := { lookup := tt }.
\end{lstlisting}


%One useful operation we need before we get to Quote relates to variables and expression evaluation. 
 As its name suggests, \lstinline|map_var| maps an expression's variable indices.
This reindexing function is the the \lstinline|map| of the \lstinline|Expr|-monad.

\begin{lstlisting}
Definition map_var {V W: Type} (f: V → W):
    Expr V → Expr W :=
  fix F (e: Expr V): Expr W :=
    match e with
    | Mult a b => Mult (F a) (F b)
    | Zero => Zero
    | Var v => Var (f v)
    end.
\end{lstlisting}

In \lstinline|Quote| below, the idea is that \lstinline|V, l|, and \lstinline|n| are all input variables, while \lstinline|V'| and \lstinline|r| are
output variables (in the sense that we will rely on unification to generate them). \lstinline|V| and \lstinline|l|
represent the current heap, \lstinline|n| represents the value we want to quote, and \lstinline|V'| and \lstinline|r'| represent
the heap of newly encountered variables during the quotation.
  This explains the type of quote: it is an expression that refers either to variables from
the old heap, or to newly encountered variables. Finally, \lstinline|eval_quote| is the usual correctness property, which now merges the two heaps.

\begin{lstlisting}
  Class Quote {V} (l: Vars V) (n: Value) {V'} (r: Vars V') :=
    { quote: Expr (V + V')
    ; eval_quote: @eval (V+V') (merge l r) quote = n }.
\end{lstlisting}


Our first instance for \lstinline|Zero| is easy. The `novars' in the result type reflects the fact that no
new variables are encountered.
\begin{lstlisting}
  Global Program Instance quote_zero V (v: Vars V):
    Quote v 0 novars := { quote := Zero }.
\end{lstlisting}


The instance for multiplication is a bit more complex. The first line consists of
 variable declarations. The second line is important. `Quote x y z' must be read as
 `quoting y with existing heap x generates new heap z', so the second line basically just
shuffles heaps around.
 The third line contains some \lstinline|map_var|'s because the heap shuffling must be
reflected in the variable indices, but apart from that it is just constructing a \lstinline|Mult| term with
quoted subterms.

\begin{lstlisting}
Global Program Instance quote_mult V (v: Vars V)
  n V' (v': Vars V') m V'' (v'': Vars V'')
  `{!Quote v n v'} `{!Quote (merge v v') m v''}:
  Quote v (n * m) (merge v' v'') :=
  { quote := Mult (map_var bla (quote n)) (map_var sum_assoc (quote m)) }.
\end{lstlisting}

The instance where we recognize values that are already in the heap is expressed by the Lookup requirement, which will only be fulfilled if the Lookup instances defined above can find the value in the heap. The novars in the \lstinline|Quote v x novars| result
   reflects that this quotation does not generate new variables.

\begin{lstlisting}
Global Program Instance quote_old_var
  V (v: Vars V) x {i: Lookup x v}:
  Quote v x novars | 8 := { quote := Var (inl (lookup x v)) }.
\end{lstlisting}


\noindent Finally, the instance for new variables. We give this a lower priority so that it is only
used if Lookup fails. The \lstinline|8| in the previous example is a random number less than \lstinline|9| below. 
%A similar method is used in Coq's notation mechanism.
% We recommend a change in
% implementation supporting an agda style precedence relation which is only restricted to be a
% directed acyclic graph~\cite{danielsson2009parsing}.

\begin{lstlisting}
Global Program Instance quote_new_var V (v: Vars V) x:
  Quote v x (singlevar x) | 9 := { quote := Var (inr tt) }.
\end{lstlisting}


We have defined a light-weight quoting function. The following code turns the goal into \lstinline|(eval variable_pack quote)|.
Here \lstinline|eval_quote'| is a modification of \lstinline|eval_quote| which works in the empty context:
\begin{lstlisting}
Goal Π x y (P: Value $\to$ Prop), P ((x * y) * (x * 0)).
  intros. rewrite <- (eval_quote' _).
\end{lstlisting}

We have used this technique to implement a tactic to normalize monoid expressions.
%It would be interesting to use this technique to implement the \lstinline|congruence| tactic, which implements
%the congruence closure algorithm~\cite{corbineau2007deciding}. One would naturally obtain a tactic
%which moreover works on setoid equalities.

\section{Canonical structures}\label{canonical}
Packed classes use canonical structures for the algebraic hierarchy. Both canonical structures and
type classes may be seen as instances of hints in unification~\cite{Hints}. Some uses of canonical
structures can be replaced by type class instances. The user manual (2.7.15) uses canonical
structures to derive the setoid equality on the natural
numbers in the following example \lstinline|(S x)==(S y)|. In this case type classes provide similar proof
terms. Canonical structures give
\begin{lstlisting}
@equiv(Build_Setoid nat (@eq nat)(@eq_equivalence nat))(S x)(S y)
\end{lstlisting}

which includes an explicit proof that \lstinline|(@eq nat)| is an equivalence,
whereas we obtain \lstinline|@equiv nat (@eq nat) (S x) (S y)|.

\subsection{Big operators}
Canonical structures have been used to provide a uniform treatment~\cite{bertot2008canonical} of big
operators (like $\Pi,\sum, \max$). These operators extend a pair of a binary and a 0-ary operation
to an $n$-ary operation for any $n$. Categorically, one considers the algebra maps from non-empty
lists, lists, inhabited finite sets and finite sets to the carrier of a semigroup, monoid,
commutative semigroup, commutative monoid. Hence we want to reuse the libraries for lists etc.\ as much as possible.

Again, we can use type classes, instead of canonical structures, to deduce the relevant monoid operation:
\begin{lstlisting}
Definition seq_sum
  `{Sequence A T} `{RingPlus A} `{z: RingZero A}: T $\to$ A
  := @seq_to_monoid A T _ A ring_plus z id.
  Eval compute in seq_sum [3; 2].
\end{lstlisting}
\marginpar{Prove distributivity?}

\section{Subset types and proof irrelevance}\label{PI}
We have mentioned proof irrelevance a number of times before. It is an important theme in our
approach. The \lstinline|Program| machinery allows one to conveniently write programs with Hoare-style
pre- and post-conditions. I.e.\ functions $f: \{ A \mid P \} \to \{ B \mid Q \}$. Both side
conditions
are intended to be proof irrelevant, they are in \lstinline|Prop|. Presently, Coq does not support such subset
types, thus forcing the user to manually prove that \lstinline|f| does not depend on the proof of \lstinline|P|.
The addition of proof irrelevance and subset types to Coq is pursued by
Barras~\cite{Barras:subset,Werner08}. 
% Squash is a monad and allows many constructions: subsets, unions, images, heterogeneous equality,
% \ldots.

Our approach may be intuitively explained by `telescopic' subset types. We recall the use of telescopes in record types~\cite{pollack2000dependently}. Given a telescope\[
T=[x_1:A_1][x_2:A_2(x_1)]\cdots[x_k:A_k(x_1,\ldots,x_k)].
\]
There is an inductively defined type $\Sigma T$, with a single constructor, given by the following 
formation and introduction rule in pseudo-code for $k=2$:
\begin{align*}
 A_1 :& Type\\
 A_2 :& \Pi A_1,Type\\
\cline{1-2}
\Sigma T :& Type
\end{align*}

\begin{align*}
 \Sigma T:Type\quad a_1 &:A_1 \quad a_2 : A_2(a_1)\\
\cline{1-3}
(a_1,a_2) &: \Sigma T
\end{align*}

For our methodology to work we have to be able to transform the occurring record into a telescopic
subset $\{ A \mid  B\}$. We moreover conjecture that the terms in \lstinline|B| only depend on the
variables in \lstinline|A|, but not in \lstinline|B| itself. However, we do not need this.

We are naturally lead to the following methodology: Let $\phi$ be a statement in type
theory, i.e.\ an alternation of $\Pi$s and $\Sigma$s. By the type theoretic axiom of choice, we first Skolemize to $\Sigma \overrightarrow{h}. \Pi \overrightarrow{a}. P$ and then transfer the variable $\overrightarrow{h}$ to the parameters. Concretely, the statement of surjectivity is skolemized to a surjection with an explicit right inverse, i.e.\ a split epi. We move the right inverse to the parameters. As a side effect, the distinction between classical and constructive mathematics virtually disappears for such explicit statements.

The addition of implicit Σ-types to Coq would change many things. Perhaps it would even allow us
to pack the proofs together with the operations, but it is too early to tell.

\subsection{Propositions as Types}
As originally conceived~\cite{ITT,CMCP}, Propositions are Types and we can extract information from
them. Often we do \emph{not} want functions to depend on proofs. In Coq, this is the paradigmatic way of working. We are forbidden to extract information from proofs of \lstinline|Prop|s. Especially with the aid of the Program machinery, this allows us to flexibly work with simply typed program and their Hoare style correctness proofs. However, we would also like to use Coq as a dependently typed programming language. This requires a hybrid approach, were we put informative propositions in \lstinline|Type| and non-informative ones in \lstinline|Prop|. Making Harrop formulas proof irrelevant seems to be a good first approximation~\cite{lcf:spi:03}. An orthogonal and further reaching proposal is to replace the Coq type theory with the Calculus of implicit constructions with implicit
Σ-types~\cite{miquel2001implicit,barras2008implicit,Bernardo}. 

%One may be tempted to propose Propositions as [ ]-types~\cite{awodey2004propositions}. Here the
%construction $[P]:=\{\top\mid p:P\}$ squashes all the information about how we proved $P$. In Coq,
%the [ ]-types are isomorphic to the type of sort \lstinline|Prop|. However,
%there are places where we needed proof \emph{relevance}; e.g.\ in the proof of the first isomorphism
%theorem above.In practice, manual dead-code analysis seems useful. Making Harrop formulas proof
%irrelevant seems to be a good first approximation~\cite{lcf:spi:03}. However, a further refinement
%of Propositions as types seems necessary.

\section{Conclusions}
Telescopes have been criticized~\cite{Packed} for the lack of multiple inheritance and
the efficiency penalty of a long chain of coercion projections. Packed classes~\cite{Packed} provide
a solution to these problems. We have provided an alternative solution based on type classes. 

We conclude that unification hints, canonical structures and type classes all appear to have
similar expressive power. Canonical structures, being tied to the unifier, are more robust, but
seem to require more ingenuity. Type classes are easier to use. Unification hints, may be a
good generalization, but are absent from Coq. We encourage their inclusion to the
Coq system.

An obvious topic for future research is the extension from equational logic to partial Horn
logic~\cite{palmgren2007partial}. Another topic would be to fully, but practically, embrace the
categorical approach to universal algebra~\cite{pitts2001categorical}.

According to \lstinline|coqwc|, our development consists of 4895 lines of
specifications and 769 lines of proofs.\marginpar{update,targz}

% Alt-Ergo congruence closure parametrized by an equational theory.
% As usual either implement in Coq (verify the algorithm), or Check traces, or Check Alt-Ergo (Work
% in progress).

% http://lara.epfl.ch/dokuwiki/sav09:congruence_closure_algorithm_and_correctness
% I understand that this is the algorithm underlying congruence and perhaps first-order.
% 
% Type classes vs soft typing (Mizar types).
% Type classes and types in homalg?

\paragraph{Acknowledgements.}
This research was stimulated by the new possibilities provided by the introduction of type classes
in Coq. In fact, this seems to be the first substantial development that tries to exploit all their
possibilities. As a consequence, we found many small bugs and unintended behavior in the type
class implementation. All these issues were quickly solved by Matthieu Sozeau. Discussions with
Georges Gonthier and Claudio Sacerdoti Coen have helped to
sharpen our understanding of the relation with Canonical Structures and with Unification Hints.
%Jeremy, Thierry
\bibliographystyle{plain}
\bibliography{alg}
\end{document}